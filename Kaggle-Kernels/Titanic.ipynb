{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv as csv\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nprint(os.listdir('../input/titanic/'))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":23,"outputs":[{"output_type":"stream","text":"['gender_submission.csv', 'test.csv', 'train.csv']\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#loading the data sets from the csv files\nprint('--------load train & test file------')\ntrain_dataset = pd.read_csv('../input/titanic/train.csv')\ntest_dataset = pd.read_csv('../input/titanic/test.csv')\n\nprint('train dataset: %s, test dataset %s' %(str(train_dataset.shape), str(test_dataset.shape)) )\ntrain_dataset.head()","execution_count":2,"outputs":[{"output_type":"stream","text":"--------load train & test file------\ntrain dataset: (891, 12), test dataset (418, 11)\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Id is unique.') if train_dataset.PassengerId.nunique() == train_dataset.shape[0] else print('oops')\nprint('Train and test sets are distinct.') if len(np.intersect1d(train_dataset.PassengerId.values, test_dataset.PassengerId.values))== 0 else print('oops')\n# print('We do not need to worry about missing values.') if train_dataset.count().min() == train_dataset.shape[0] and test_dataset.count().min() == test_dataset.shape[0] else print('oops we have nan')\n\ndatasetHasNan = False\nif train_dataset.count().min() == train_dataset.shape[0] and test_dataset.count().min() == test_dataset.shape[0] :\n    print('We do not need to worry about missing values.') \nelse:\n    datasetHasNan = True\n    print('oops we have nan')","execution_count":3,"outputs":[{"output_type":"stream","text":"Id is unique.\nTrain and test sets are distinct.\noops we have nan\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('----train dataset column types information-------')\ndtype_df = train_dataset.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","execution_count":4,"outputs":[{"output_type":"stream","text":"----train dataset column types information-------\n","name":"stdout"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"  Column Type  Count\n0       int64      5\n1     float64      2\n2      object      5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column Type</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>int64</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>float64</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>object</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('----train dataset information-------')\ndtype_df","execution_count":5,"outputs":[{"output_type":"stream","text":"----train dataset information-------\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"          Count Column Type\n0   PassengerId       int64\n1      Survived       int64\n2        Pclass       int64\n3          Name      object\n4           Sex      object\n5           Age     float64\n6         SibSp       int64\n7         Parch       int64\n8        Ticket      object\n9          Fare     float64\n10        Cabin      object\n11     Embarked      object","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Count</th>\n      <th>Column Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PassengerId</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Survived</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pclass</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Name</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sex</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Age</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SibSp</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Parch</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Ticket</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Fare</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Cabin</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Embarked</td>\n      <td>object</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for missing data & list them \nif datasetHasNan == True:\n    nas = pd.concat([train_dataset.isnull().sum(), test_dataset.isnull().sum()], axis=1, keys=['Train Dataset', 'Test Dataset']) \n    print('Nan in the data sets')\n    print(nas[nas.sum(axis=1) > 0])","execution_count":6,"outputs":[{"output_type":"stream","text":"Nan in the data sets\n          Train Dataset  Test Dataset\nAge                 177          86.0\nFare                  0           1.0\nCabin               687         327.0\nEmbarked              2           0.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class vs Survived\nprint(train_dataset[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))","execution_count":7,"outputs":[{"output_type":"stream","text":"   Pclass  Survived\n0       1  0.629630\n1       2  0.472826\n2       3  0.242363\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sex vs Survived\nprint(train_dataset[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))","execution_count":8,"outputs":[{"output_type":"stream","text":"      Sex  Survived\n0  female  0.742038\n1    male  0.188908\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SibSp vs Survived\n#Sibling = brother, sister, stepbrother, stepsister\n#Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\nprint(train_dataset[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))","execution_count":9,"outputs":[{"output_type":"stream","text":"   SibSp  Survived\n1      1  0.535885\n2      2  0.464286\n0      0  0.345395\n3      3  0.250000\n4      4  0.166667\n5      5  0.000000\n6      8  0.000000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parch vs Survived\n#Parent = mother, father\n#Child = daughter, son, stepdaughter, stepson\n#Some children travelled only with a nanny, therefore parch=0 for them.\nprint(train_dataset[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))","execution_count":10,"outputs":[{"output_type":"stream","text":"   Parch  Survived\n3      3  0.600000\n1      1  0.550847\n2      2  0.500000\n0      0  0.343658\n5      5  0.200000\n4      4  0.000000\n6      6  0.000000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data sets cleaing, fill nan (null) where needed and delete uneeded columns\nprint('----Start data cleaning ------------')\n\n\n#manage Age\ntrain_random_ages = np.random.randint(train_dataset[\"Age\"].mean() - train_dataset[\"Age\"].std(),\n                                          train_dataset[\"Age\"].mean() + train_dataset[\"Age\"].std(),\n                                          size = train_dataset[\"Age\"].isnull().sum())\n\ntest_random_ages = np.random.randint(test_dataset[\"Age\"].mean() - test_dataset[\"Age\"].std(),\n                                          test_dataset[\"Age\"].mean() + test_dataset[\"Age\"].std(),\n                                          size = test_dataset[\"Age\"].isnull().sum())\n\ntrain_dataset[\"Age\"][np.isnan(train_dataset[\"Age\"])] = train_random_ages\ntest_dataset[\"Age\"][np.isnan(test_dataset[\"Age\"])] = test_random_ages\ntrain_dataset['Age'] = train_dataset['Age'].astype(int)\ntest_dataset['Age']    = test_dataset['Age'].astype(int)\n\n# Embarked \ntrain_dataset[\"Embarked\"].fillna('S', inplace=True)\ntest_dataset[\"Embarked\"].fillna('S', inplace=True)\ntrain_dataset['Port'] = train_dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ntest_dataset['Port'] = test_dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ndel train_dataset['Embarked']\ndel test_dataset['Embarked']\n\n# Fare\ntest_dataset[\"Fare\"].fillna(test_dataset[\"Fare\"].median(), inplace=True)","execution_count":11,"outputs":[{"output_type":"stream","text":"----Start data cleaning ------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  from ipykernel import kernelapp as app\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature that tells whether a passenger had a cabin on the Titanic\ntrain_dataset['Has_Cabin'] = train_dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest_dataset['Has_Cabin'] = test_dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n\n# engineer a new Title feature\n# group them\nfull_dataset = [train_dataset, test_dataset]\n\n##engineer the family size feature\nfor dataset in full_dataset:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n### new try \n\n# Create new feature IsAlone from FamilySize\nfor dataset in full_dataset:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \n##############################\n\n\n# Get titles from the names\ntrain_dataset['Title'] = train_dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_dataset['Title'] = test_dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nfor dataset in full_dataset:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n\n    \n## Create new column \"FamilySizeGroup\" and assign \"Alone\", \"Small\" and \"Big\"\nfor dataset in full_dataset:\n    dataset['FamilySizeGroup'] = 'Small'\n    dataset.loc[dataset['FamilySize'] == 1, 'FamilySizeGroup'] = 'Alone'\n    dataset.loc[dataset['FamilySize'] >= 5, 'FamilySizeGroup'] = 'Big'\n\n## Get the average survival rate of different FamilySizes\ntrain_dataset[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean()\n\nfor dataset in full_dataset:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n        \nfor dataset in full_dataset:    \n    dataset.loc[ dataset['Age'] <= 14, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 14) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n\nfor dataset in full_dataset:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# map the new features\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfamily_mapping = {\"Small\": 0, \"Alone\": 1, \"Big\": 2}\nfor dataset in full_dataset:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['FamilySizeGroup'] = dataset['FamilySizeGroup'].map(family_mapping)\n\n# engineer a new  features\nfor dataset in full_dataset:\n    dataset['IsChildandRich'] = 0\n    dataset.loc[(dataset['Age'] <= 0) & (dataset['Pclass'] == 1 ),'IsChildandRich'] = 1  \n    dataset.loc[(dataset['Age'] <= 0) & (dataset['Pclass'] == 2 ),'IsChildandRich'] = 1  \n    \n\n    \n# Delete Name column from datasets (No need for them in the analysis)\ndel train_dataset['Name']\ndel test_dataset['Name']\n\ndel train_dataset['SibSp']\ndel test_dataset['SibSp']\n\ndel train_dataset['Parch']\ndel test_dataset['Parch']\n\ndel train_dataset['FamilySize']\ndel test_dataset['FamilySize']\n\n\ndel train_dataset['Cabin']\ndel test_dataset['Cabin']\n\n# Delete Ticket column from datasets  (No need for them in the analysis)\ndel train_dataset['Ticket']\ndel test_dataset['Ticket']\n\ndel train_dataset['Port']\ndel test_dataset['Port']\n\n\nprint('----Finish data cleaning ------------')","execution_count":13,"outputs":[{"output_type":"stream","text":"----Finish data cleaning ------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train dataset: %s, test dataset %s' %(str(train_dataset.shape), str(test_dataset.shape)) )\ntrain_dataset.head()","execution_count":14,"outputs":[{"output_type":"stream","text":"train dataset: (891, 11), test dataset (418, 10)\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"   PassengerId  Survived  Pclass  Sex  Age  Fare  Has_Cabin  IsAlone  Title  \\\n0            1         0       3    0    1     0          0        0      1   \n1            2         1       1    1    2     3          1        0      3   \n2            3         1       3    1    1     1          0        1      2   \n3            4         1       1    1    2     3          1        0      3   \n4            5         0       3    0    2     1          0        1      1   \n\n   FamilySizeGroup  IsChildandRich  \n0                0               0  \n1                0               0  \n2                1               0  \n3                0               0  \n4                1               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Has_Cabin</th>\n      <th>IsAlone</th>\n      <th>Title</th>\n      <th>FamilySizeGroup</th>\n      <th>IsChildandRich</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_dataset['PassengerId']\n\nX_train = train_dataset.drop(\"Survived\",axis=1)\nY_train = train_dataset[\"Survived\"]\nX_test  = test_dataset.drop(\"PassengerId\",axis=1).copy()\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)","execution_count":15,"outputs":[{"output_type":"stream","text":"(891, 9)\n(891,)\n(418, 9)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create model\nmodel = Sequential()\n\n#get number of columns in training data\nn_cols = X_train.shape[1]\n\n#add model layers\nmodel.add(Dense(10, activation='relu', input_shape=(n_cols,)))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1))","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compile model using mse as a measure of model performance\nmodel.compile(optimizer='adam', loss='mean_squared_error')","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set early stopping monitor so the model stops training when it won't improve anymore\nearly_stopping_monitor = EarlyStopping(patience=3)\n#train model\nmodel.fit(X_train, Y_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])","execution_count":24,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n23/23 [==============================] - 0s 9ms/step - loss: 2.3642 - val_loss: 1.2133\nEpoch 2/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.7331 - val_loss: 0.5217\nEpoch 3/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.4036 - val_loss: 0.3230\nEpoch 4/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.2849 - val_loss: 0.2525\nEpoch 5/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.2437 - val_loss: 0.2215\nEpoch 6/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.2270 - val_loss: 0.2069\nEpoch 7/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.2163 - val_loss: 0.1979\nEpoch 8/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.2088 - val_loss: 0.1911\nEpoch 9/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.2016 - val_loss: 0.1836\nEpoch 10/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1953 - val_loss: 0.1812\nEpoch 11/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1900 - val_loss: 0.1732\nEpoch 12/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.1690\nEpoch 13/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1789 - val_loss: 0.1665\nEpoch 14/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1747 - val_loss: 0.1605\nEpoch 15/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.1606\nEpoch 16/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1685 - val_loss: 0.1560\nEpoch 17/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1651 - val_loss: 0.1541\nEpoch 18/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1630 - val_loss: 0.1495\nEpoch 19/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1606 - val_loss: 0.1476\nEpoch 20/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1584 - val_loss: 0.1444\nEpoch 21/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1573 - val_loss: 0.1471\nEpoch 22/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1420\nEpoch 23/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1423\nEpoch 24/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1392\nEpoch 25/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1403\nEpoch 26/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.1373\nEpoch 27/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1482 - val_loss: 0.1368\nEpoch 28/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1318\nEpoch 29/30\n23/23 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.1342\nEpoch 30/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.1357\n","name":"stdout"},{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f1d5c74e690>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making predictions on out testing data\npredictions = model.predict(X_test)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred = predictions.reshape(-1)\n# print(pred)","execution_count":30,"outputs":[{"output_type":"stream","text":"[ 0.19236092  0.78237724  0.19954629  0.15520093  0.5487697   0.07715257\n  0.53046995  0.12171848  0.5465522   0.10742275  0.19236092  0.15904574\n  1.1197127   0.09308524  1.1395719   0.865301    0.19632502  0.13713881\n  0.51548237  0.71296793  0.07906875  0.20763536  0.9553679   0.25390407\n  0.8221816   0.0787894   0.98897344  0.13713881  0.3949646   0.10742275\n  0.09308536  0.10330822  0.7853009   0.7853009   0.51306677  0.13713881\n  0.5766199   0.5733988   0.15520093  0.18256135  0.07681204  0.47744587\n  0.19236092  0.624584    1.1395719   0.15520093  0.3949646   0.13713881\n  1.0841136   0.7853009   0.51306677  0.20001961  0.70251215  0.8190494\n  0.20001961  0.15922536  0.19236092  0.24464233  0.09310599  0.9105534\n  0.13713881  0.19310401  0.13713886  0.5304697   0.6161156   0.84012115\n  0.53046995  0.22386058  0.47744587  0.75793624  0.53046995  0.13713881\n  0.5733988   0.47744587  0.9105534   0.55276245  0.15520093  1.0736878\n  0.19310401  0.53046995  0.47439584  0.29335383  0.08922394  0.19236092\n  0.19632502  0.10742275  0.53046995  0.5733988   0.53046995  0.56723964\n  0.5487697   0.13713881  1.1197127   0.15842198  0.28229287  0.13713886\n  1.0879543   0.15520093  0.53046995  0.15842198  1.1395719   0.12171848\n  0.13713881  0.13713881  0.5487697   0.11774652  0.13713881  0.13713881\n  0.15842198  0.33007845  0.08924476  0.53046995  0.9105534   0.53046995\n  1.1022708   0.10742275  0.19236092  0.822975    0.45977953  0.865301\n  0.7620786   0.15344141  1.1395719   0.13713881  0.13713881  0.6882161\n  0.13713886  0.6882164   0.19632502  0.15520093  0.15520093  0.7978665\n  0.55075926  0.15344141  0.19236092  0.13713881  0.13713881  0.19310401\n  0.5733988  -0.1982894   0.51358724  0.6706247   0.07892877  0.20001961\n  0.15904574  0.10742275  0.55276245  0.15520093  0.2822928   0.55129504\n  1.1197127   0.13713881  0.06063215  0.57329094  0.24029125  0.13713881\n  1.0568444   0.53046995  0.3949647   0.5487696   0.61055905  0.47439584\n  0.60850173  0.13713881  0.44591495  0.79131395  0.45977953 -0.07504228\n  0.887677    0.5733988   0.13713881  0.13713881  0.06699927  0.19236092\n -0.1982894   0.62939036  0.71159846  0.32658562  1.1062003   1.1022708\n  0.19310401  0.37888     1.1197127   0.13713881  1.1197127   0.08924476\n  0.70251215  0.06699927  0.3717217   0.19632502  0.1074018   0.1590458\n  0.47439584  0.19954629  0.61052096  0.19236092  0.76845807  0.53046995\n  0.19310401  0.5896557   0.6700591   0.25980332  0.9635701   0.7772785\n  0.19310401  0.2822928   0.61055905  0.19310401  0.9042015   0.13713881\n  0.11774652  0.13713881  0.2648345   0.8526859   0.25455776  0.45977953\n  0.61055905  0.07906875  1.1022708   0.15842198  0.58824366  0.15520093\n  0.77755445  0.13713886  0.8823006   0.79131395  0.13713881  0.53046995\n  0.07494873  0.19632502  0.41314065  0.72905654  0.15344141  0.19236092\n  0.37888     0.13713881  0.32658562  0.13713881  0.58824366  1.1395719\n  0.8823006   0.8580623   0.37888     0.19236092  0.42923525  0.37888\n  0.84012115  0.07225814  0.865301    0.79131395  0.7772785   0.15520093\n  0.51306677  0.15520093  0.15520126  0.13713886  0.13713881  0.15520093\n  0.60850173  0.13713881  0.09310599  0.13713881  0.865301    0.5514942\n  0.19310401  0.19236092  0.26816717  0.19236092  0.5766199   0.15520093\n  0.45977953  0.13713881  1.1197127   0.6882161   0.13713881  0.70251215\n  0.19310401  0.10740183  0.12171848  0.19310401  0.5733988   0.25980332\n  0.61055905  0.6962773   0.6962773   0.19236092  0.19236101  0.51306665\n  0.24464233  0.15520093  0.35303688  0.53046995  0.19236092  0.9657694\n  0.15842198  0.13713881  0.7639083   0.09310599  0.35303688  0.13713881\n  0.13713881  0.31269172  0.10740183  0.15520093  0.53046995  1.0736878\n  0.51306677  0.25980332  0.32658562  0.57329094  0.15520093  0.13713881\n  0.13713881  0.61055905  1.0841136   0.53046995  0.32658562  0.19310401\n  0.13713886  0.10330822  0.13713881  0.24464233  0.33007845  0.15904574\n  0.6706247   0.13713881  1.0184778   0.22386058  0.12171848  0.19310401\n  0.8824242   0.3949646   0.13713881  0.79131395  0.13713881  0.47744587\n  0.19310401  0.18731345  0.2648345   0.35880002  0.19310401  0.13713881\n -0.1982894   1.1022708   0.42923525  0.53046995  0.19310401  0.71296793\n  0.19310401  0.68435484  1.139572    0.19310406  0.2648345   0.05794173\n  0.6962773   0.3090913   1.1022708   0.19236092  0.19236092  0.79131395\n  0.24029125  0.88158643  0.84012115  0.15520093  1.1197127   0.5381106\n  0.10742275  0.63491553  0.834797    0.19310401  0.13976054  1.0568444\n  0.53189963  0.19632502  1.1022708   0.6706247   0.51548237  0.19310401\n  0.3365325   0.24029125  0.13713881  0.13713881  0.7421546   0.79131395\n  0.19632502  0.62939036  0.13713881  0.19954629  0.13713881  0.15922536\n  0.55276245  1.1022708   0.47439584  0.19632502 -0.12173414  1.1197127\n  0.13713881  1.1395719   0.13713881  0.13713881  1.0568444   0.10740183\n  0.56869143  0.35303688  0.34803548  0.33007845  0.13976054  0.32658562\n  0.53046995  0.5514942   0.53046995  1.1395719   0.53046995  0.15842198\n  1.33623     0.19236101  0.15842198  0.42923543]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'PassengerId': test_dataset.PassengerId, 'Survived': pred})\nsubmission.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":31,"outputs":[{"output_type":"stream","text":"Your submission was successfully saved!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}